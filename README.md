# Тестовый проект - анализатор репозитория GitHub с выводом полученной информации в stdout

[Ссылка на описание тестового задания](https://drive.google.com/open?id=1iDiNPnQgr1GkIDNNi-75wfLYx0M939eB)

## Замечания по реализации

Документация в классе и методах, а также вывод анализав в консоли сделаны по-английски, чтобы дать представление о возможностях автора писать и понимать по-английски.)

Исходный код проекта разбит на 3 класса, выполняющих свою часть работы:

- `GitHubAPIWrapper` - обёртка для подготовки и отправки запросов к GitHub REST API v3.
- `GitHubRepoAnalyzer` - анализатор полученных исходных данных.
- `GitHubRepoAnalyzePresenter` - вывод данных ангализа в *stdout*.

Поскольку по условию задания вывод результаты анализа должны выводиться в *stdout*, это подразумевает запуск модуля в консоли (терминале), что возможно благодаря пакету `argparse`. Также при работе в *Linux* можно указать в файле `.bashrc` псевдоним, например, `alias github_repo_analyzer='path/to/project/run.py'`, чтобы иметь возможность запускать модуль напрямую без расширения `.py`.

Для запуска модуля в консоли необходимо запускать исполняемый файл `run.py` с одним обязательным и несколькими опциональными аргументами командой вида `python run.py {repo_url} {optional_arguments}`:

* `repo_url` - URL репозитория на GitHub, например, `https://github.com/fastlane/fastlane/`.

Все ключевые параметры - опциональные:

* `-f` - Начальная дата для фильтрации по времени в формате ISO 8601, например, `2018-02-23` (`from_date`).
* `-t` - Конечная дата для фильтрации по времени в формате ISO 8601, например, `2018-03-08` (`to_date`).
* `-b` - Ветка репозитория для фильтрации по ветке (по умолчанию - `master`) (`branch`).

Для удобства использования параметры, которые могут при желании быть изменены пользователем, указаны как опциональные аргументы со значениями по умолчанию:

* `-c` - Максимальное число контрибьюторов для вывода в таблице, по умолчанию - `30` (`authors_max`).
* `-p` - Число дней для обозначения pull request как "старого", по умолчанию - `30` (`old_pulls_days`).
* `-i` - Число дней для обозначения issue как "старого", по умолчанию - `14` (`old_issues_days`).

Частые запросы с одного IP-адреса могут на какое-то время блокироваться серверами GitHub. В этом случае в процессе ваыполнения очередного запроса пользователю будет выдано предупреждающее сообщение. Для обохда блокировок можно воспользоваться опциональным ключом `-a` (булев ключ без значения) для ввода пользовательского ключа аутентификации *OAuth*, создаваемого в личном кабинете на сайте GitHub. С указанием этого ключа при выполнении команды в консоли появляется возможность ввода с подписью `Access token: `. Это сделано для того, чтобы секретный ключ не запоминался в истории ввода консольных команд. Если ключ `-a` используется, но секретный ключ не введён - запрос не выполняется. Этот ключ также можно указать непосредственно в словаре `kwargs` в исходном коде `run.py`, чтобы не вводить его каждый раз вручную.

* `-a` - Пользовательский ключ аутентификации *OAuth* (`auth_token`).

## Фильтрация результатов

Фильтр по дате имеет смысл, если выполняется одно из условий:

* задана только начальная дата,
* задана только конечная дата,
* задана и начальная дата, и конечная дата, при этом конечная дата больше или равна начальной (если они равны - поиск происходит строго по одной этой дате).

Если конечная дата меньше начальной - выводится предупреждающее сообщение без запуска анализа, т.к. мы в любом случае ничего не сможем найти по этому условию.

Если одна или обе даты введены некорректно (не по маске *ISO 8601*), они сбрасываются в `None` и не используются при фильтрации (в этом случае используется только фильтарция по ветке). При желании можно было бы воспринимать факт ошибки в дате как исключение и не выполнять проверку в этом случае.

Фильтр по ветке работает всегда, даже если она явно не задана, т.к. а этом случае берётся значение по умолчанию `master`.

## Обработка возможной пагинации результатов

Перед отправкой GET-запросов к API GitHub для получения информации предварительно отправляется HEAD-запрос с тем же *query string* для получения параметра `last` в заголовке `Link`, содержащего число страниц с пагинацией, если данные в результате достаточно объёмные и не умещаются на одну страницу с максимально возможным числом записей (`100`).

Затем:

* если пагинация присутствует - делается серия последовательных GET-запросов для получения всех страниц,
* если пагинация отсутствует - делается один GET-запрос без пагинации.

Заголовок `link` также содержит URL-адреса для отправки запросов с пагинацией вида `https://api.github.com/repositories/{REPO_ID}/{RESOURCE}?{OPTIONAL_QUERY_STRING}&page=3`. При тестировании обнаружилось, что подстановка номера станицы `page` в query string стандартного URL метода API (например, `https://api.github.com/repos/{REPO_OWNER}/{REPO_TITLE}/commits`) даёт те же результаты, поэтому сам URL из заголовка `Link` не используются.

Данные подсчитываются в атрибуте `counters` - это словарь, содержащий счётчики `collections.Counter` соответствующих сущностей (`contributors`, `pulls` и `issues`). Кроме того, для красивого вывода информации о контрибьюторах в таблице формируется отдельный атрибут `contributors_list` - список из словарей с информацией о каждом найденном контрибьюторе, упорядоченный по убыванию числа их коммитов.

## Вывод информации в stdout

Анализ полученных данных репозитория выполняется в экземпляре класса `GitHubRepoAnalyzer`, а вывод полученной информации - в экземпляре класса `GitHubRepoAnalyzePresenter`.

Вывод таблицы контрибьюторов делается с помощью строкового форматирования. При получении имени пользователя, символы которого несовместимы с *ASCII*-символами, его длина вычисляется правильно с помощью метода `unicodedata.normalize`. При использовании Python 2 вывод имени пользователя обрабатывает исключения декодирования Юникода - имя пользователя конвертируется в *ASCII*-совместимую строку.

Для экономии длины строки при формировании таблицы используется конкатенация строк с помощью символов `+`, что в общем случае, очевидно, не является хорошей практикой в сравнении с методом `format` или `f`-форматированием в Python 3.6.

Можно было бы внедрить подсветку кода с помощью цветовых кодов *BASh*, но за нехваткой времени это не было реализовано.

## Поддержка версий Python

Я постарался сделать задание рабочим и в Python 2, и в Python 3 (работа проверялась на Ubuntu 16.04 в Python 2.7.12 и Python 3.5.2). [С другой стороны...](https://pythonclock.org/).

## Вопросы по условиям задания

В условии прямо не сказано, стоит ли анализировать всю возможную информацию в получаемом ответе или нужно прекратить делать запросы, например, набрав максимальное число контрибьюторов (по условию задания - `30`). В больших проектах пагинация даже по 100 записей на странице может достигать нескольких десятков страниц, если не больше.

Во-первых, это - очень большое число частых запросов с одного IP-адреса, за что без ключа аутентификации IP-адрес могут временно забанить. Для этого предусмотрена опция `-a` для ввода опционального пользовательского ключа аутентификации *OAuth*.

Во-вторых, это сильно замедляет выполение анализа для больших проектов.

Но, поскольку для получения списка контрибьюторов, упорядоченного по убыванию их вклада в проект, нам нужно в любом случае просмотреть всё содержимое ответа, запросы не отменяются и проводятся полностью, сколько бы их ни требовалось.

В условиях прямо не сказано, что брать за основу при фильтрации pull requests по ветке - `head` или `base`. В решении выбрана фильтрация по `base` как по ветке, в которую происходит слияние. Фильтрация по `base` происходит непосредственно в query string GET-запроса. В списке получаемых pull requests есть возможность дополнительно фильтровать их по ключу `['base']['ref']`, но этот ключ может присутствовать не во всех pull requests, поэтому это не было реализовано.

Исходя из документации к GitHub API, issues нельзя фильтровать по веткам, т.к. они к ним не привязаны, только по дате. Я не был уверен, стоит ли фильтровать получаемые issues (как и pull requests) по ключу `['default_branch']`, поэтому это не было реализовано.
